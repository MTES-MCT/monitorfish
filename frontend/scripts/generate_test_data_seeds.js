/* eslint-disable import/no-extraneous-dependencies, no-await-in-loop, no-restricted-syntax */

import { promises as fs } from 'fs'
import { join } from 'path'
import stripJsonComments from 'strip-json-comments'

const SOURCE_DIRECTORY_PATH = join(import.meta.url, '../../../backend/src/main/resources/db/testdata/json').replace(
  'file:',
  ''
)
const TARGET_DIRECTORY_PATH = join(import.meta.url, '../../../backend/src/main/resources/db/testdata').replace(
  'file:',
  ''
)

function setJsonbSqlPropsToNull(obj) {
  const processObject = currentObj => {
    const processedObj = Array.isArray(currentObj) ? [] : {}
    Object.entries(currentObj).forEach(([key, value]) => {
      if (Array.isArray(value)) {
        processedObj[key] = value.map(valueItem => processObject(valueItem))
      } else if (typeof value === 'object' && value !== null) {
        processedObj[key] = processObject(value)
      } else {
        // Temporarily set :jsonb > :sql properties to null in the `INSERT` statement
        // so that they can be updated with subsequent `UPDATE` statements
        processedObj[key] = key.endsWith(':sql') ? null : value
      }
    })

    return processedObj
  }

  return `'${JSON.stringify(processObject(obj)).replace(/:sql"/g, '"').replace(/'/g, "''")}'`
}

function generateInsertStatement(row, table) {
  const sqlColumns = []
  const sqlValues = []

  const rowAsKeyValuePairs = Object.entries(row)

  for (const [key, value] of rowAsKeyValuePairs) {
    const sqlColumn = key.replace(/:(jsonb|sql)$/, '')
    if (key.endsWith(':jsonb')) {
      const sqlValue = setJsonbSqlPropsToNull(value)

      sqlColumns.push(sqlColumn)
      sqlValues.push(sqlValue)
    } else if (Array.isArray(value)) {
      const valueAsSqlArray =
        value.length > 0 ? `'{"${value.map(valueItem => valueItem.replace(/'/g, "''")).join('", "')}"}'` : "'{}'"

      sqlColumns.push(sqlColumn)
      sqlValues.push(valueAsSqlArray)
    } else if (value === null) {
      sqlColumns.push(sqlColumn)
      sqlValues.push('NULL')
    } else if (typeof value !== 'string' || key.endsWith(':sql')) {
      sqlColumns.push(sqlColumn)
      sqlValues.push(value)
    } else {
      const valueAsSqlString = `'${value.replace(/'/g, "''")}'`

      sqlColumns.push(sqlColumn)
      sqlValues.push(valueAsSqlString)
    }
  }

  return `INSERT INTO ${table} (${sqlColumns.join(', ')}) VALUES (${sqlValues.join(', ')});`
}

function generateUpdateStatements(row, table, id) {
  const idColumnName = id ?? 'id'
  const updates = []

  const processUpdates = (obj, path = []) => {
    Object.entries(obj).forEach(([key, value]) => {
      const currentPath = [...path, key.replace(/:sql$/, '')]
      if (key.endsWith(':sql')) {
        const idColumnValue = row[idColumnName]
        const escapedIdColumnValue =
          typeof idColumnValue === 'string' ? `'${idColumnValue.replace(/'/g, "''")}'` : idColumnValue

        updates.push(
          `UPDATE ${table} SET value = JSONB_SET(value, '{${currentPath.join(
            ','
          )}}', TO_JSONB(${value}), true) WHERE ${idColumnName} = ${escapedIdColumnValue};`
        )
      } else if (typeof value === 'object' && value !== null) {
        processUpdates(value, currentPath)
      }
    })
  }

  Object.entries(row).forEach(([key, value]) => {
    if (key.endsWith(':jsonb')) {
      processUpdates(value)
    }
  })

  return updates
}

console.info(`
######   ######   ######   ######           ######    #####    ######   #####
  ##    ##       ##          ##             ##   ##  ##   ##     ##    ##   ##
  ##    ## ###    #####      ##             ##   ##  ## ####     ##    ## ####
  ##    ##            ##     ##             ##   ##  ##   ##     ##    ##   ##
  ##     ######  ######      ##             ## ###   ##   ##     ##    ##   ##
`)

const jsonFiles = (await fs.readdir(SOURCE_DIRECTORY_PATH)).filter(file => file.endsWith('.jsonc'))
for (const file of jsonFiles) {
  const jsonFilePath = join(SOURCE_DIRECTORY_PATH, file)
  const sqlFilePath = join(TARGET_DIRECTORY_PATH, file.replace('.jsonc', '.sql'))
  const jsonSource = await fs.readFile(jsonFilePath, 'utf8')
  const jsonSourceAsObject = JSON.parse(stripJsonComments(jsonSource))

  const dataTables = Array.isArray(jsonSourceAsObject) ? jsonSourceAsObject : [jsonSourceAsObject]
  const sqlStatementBlocks = dataTables
    .map(dataTable => {
      const { afterAll, beforeAll, data: rows, id, table } = dataTable

      return [
        beforeAll,
        ...rows.map(row => {
          const insertStatement = generateInsertStatement(row, table)
          const updateStatements = generateUpdateStatements(row, table, id)

          return [insertStatement, ...updateStatements, ''].join('\n')
        }),
        afterAll
      ].filter(Boolean)
    })
    .flat()

  const sqlSource = [
    `-- /!\\ This file is automatically generated by a local script.`,
    `-- Do NOT update it directly, update the associated .jsonc file in /backend/src/main/resources/db/testdata/json/.`,
    '',
    ...sqlStatementBlocks
  ].join('\n')
  await fs.writeFile(sqlFilePath, sqlSource, 'utf8')
  console.info(`[Test Data Generator] SQL Test Data file generated at ${sqlFilePath}`)
}

console.info()
